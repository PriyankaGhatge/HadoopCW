import java.io.IOException;

import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Mapper.Context;
import org.apache.hadoop.mapreduce.Partitioner;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.util.Tool;


public class PartitionerEx extends Configured implements Tool{
	
	public static class MapperEx extends Mapper<LongWritable,Text,Text,Text>
	   {
	      public void map(LongWritable key, Text value, Context context)
	      {	    	  
	         try{
	        	 
	        	 String[] arr = value.toString().split(",");
	        	 String gender= arr[3];
	        	 context.write(new Text(gender),new Text(value));	        	 
	         }
	         catch(Exception e){
	        	 e.getMessage();
	         }
	      }
	   }
	public static class ReducerEx extends Reducer<Text,Text,Text,IntWritable>
	{
		public int max=-1;
		private Text outputkey = new Text();	
		public void reduce(Text key, Iterable<Text> values,Context context) throws IOException, InterruptedException{
			max=-1;
			for(Text val : values ){
				
				String[] arr = val.toString().split(",");
				if(Integer.parseInt(arr[4])>max){
					max=Integer.parseInt(arr[4]);
					String mykey= arr[3]+','+arr[1]+','+arr[2];
					outputkey.set(mykey);
				}
				
			}
			context.write(outputkey, new IntWritable(max));
		}
	}

	public static class Partitionerex extends Partitioner<Text,Text>{

		@Override
		public int getPartition(Text key, Text value, int numReduceTasks) {
			
			String[] arr = value.toString().split(",");
			int age=Integer.parseInt(arr[2]);
			
			if(age<=20){
				return 0;	
			}
			else if (age>20 && age<=30){
				return 1;
			}
			else {
				return 2;
			}
			
		}
		
	}
	
	
	public static void main(String[] args) {
		

	}

	public int run(String[] arg) throws Exception {
		// TODO Auto-generated method stub
		return 0;
	}

}
